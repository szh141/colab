{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtFZ9aWnrlI0NwLwi7NKww",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szh141/colab/blob/main/Simple_Unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://medium.com/@vipul.sarode007/u-net-unleashed-a-step-by-step-guide-on-implementing-and-training-your-own-segmentation-model-in-a38741776968"
      ],
      "metadata": {
        "id": "rmcyKwP73iOU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "jGi_FYBcr4An"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Srq7mOfcrBYr"
      },
      "outputs": [],
      "source": [
        "#Let's create a function for one step of the encoder block, so as to increase the reusability when making custom unets\n",
        "\n",
        "def encoder_block(filters, inputs):\n",
        "  x = Conv2D(filters, kernel_size = (3,3), padding = 'same', strides = 1, activation = 'relu')(inputs)\n",
        "  s = Conv2D(filters, kernel_size = (3,3), padding = 'same', strides = 1, activation = 'relu')(x)\n",
        "  p = MaxPooling2D(pool_size = (2,2), padding = 'same')(s)\n",
        "  return s, p #p provides the input to the next encoder block and s for skip connection in the decoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline or the bottom of the U-net\n",
        "\n",
        "same as encoder, but no MaxPooling"
      ],
      "metadata": {
        "id": "HjIASOopsNUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Baseline layer is just a bunch on Convolutional Layers to extract high level features from the downsampled Image\n",
        "def baseline_layer(filters, inputs):\n",
        "  x = Conv2D(filters, kernel_size = (3,3), padding = 'same', strides = 1, activation = 'relu')(inputs)\n",
        "  x = Conv2D(filters, kernel_size = (3,3), padding = 'same', strides = 1, activation = 'relu')(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "tRJzZDgssMn6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder\n",
        "\n",
        "Concatenate the skip connection\n",
        "\n",
        "has one more input parameter, the skip connection from the encoder"
      ],
      "metadata": {
        "id": "KmXv-UnFsgTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Decoder Block\n",
        "def decoder_block(filters, connections, inputs):\n",
        "  x = Conv2DTranspose(filters, kernel_size = (2,2), padding = 'same', activation = 'relu', strides = 2)(inputs)\n",
        "  skip_connections = concatenate([x, connections], axis = -1)\n",
        "  x = Conv2D(filters, kernel_size = (2,2), padding = 'same', activation = 'relu')(skip_connections)\n",
        "  x = Conv2D(filters, kernel_size = (2,2), padding = 'same', activation = 'relu')(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "26hnrj5OshwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U-net model"
      ],
      "metadata": {
        "id": "TKnxFgsrtQ9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unet():\n",
        "  #Defining the input layer and specifying the shape of the images\n",
        "  inputs = Input(shape = (224,224,1))\n",
        "\n",
        "  #defining the encoder\n",
        "  s1, p1 = encoder_block(64, inputs = inputs)\n",
        "  s2, p2 = encoder_block(128, inputs = p1)\n",
        "  s3, p3 = encoder_block(256, inputs = p2)\n",
        "  s4, p4 = encoder_block(512, inputs = p3)\n",
        "\n",
        "  #Setting up the baseline\n",
        "  baseline = baseline_layer(1024, p4)\n",
        "\n",
        "  #Defining the entire decoder\n",
        "  d1 = decoder_block(512, s4, baseline)\n",
        "  d2 = decoder_block(256, s3, d1)\n",
        "  d3 = decoder_block(128, s2, d2)\n",
        "  d4 = decoder_block(64, s1, d3)\n",
        "\n",
        "  #Setting up the output function for binary classification of pixels\n",
        "  outputs = Conv2D(1, 1, activation = 'sigmoid')(d4)\n",
        "\n",
        "  #Finalizing the model\n",
        "  model = Model(inputs = inputs, outputs = outputs, name = 'Unet')\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "TBVpx0PItPwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dice coefficient definition"
      ],
      "metadata": {
        "id": "JMSGejyV3NO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting dice coefficient to evaluate our model\n",
        "def dice_coeff(y_true, y_pred, smooth = 1):\n",
        "    intersection = K.sum(y_true*y_pred, axis = -1)\n",
        "    union = K.sum(y_true, axis = -1) + K.sum(y_pred, axis = -1)\n",
        "    dice_coeff = (2*intersection+smooth) / (union + smooth)\n",
        "    return dice_coeff"
      ],
      "metadata": {
        "id": "vsVRTECP3QVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "import libraries and training"
      ],
      "metadata": {
        "id": "zTWNJdOe2CXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is from the following post for categorizing images, not for U-net\n",
        "#https://pub.aimind.so/understanding-the-learning-mechanism-of-convolutional-neural-networks-19a0568df252\n",
        "\n",
        "import tensorflow as tf\n",
        "#from tensorflow.keras.datasets import mnist\n",
        "#from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D # Dense, Flatten, not need for U-net\n",
        "#from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "CEoOeroi2CFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unet = unet()\n",
        "unet.compile(loss = 'binary_crossentropy',\n",
        "            optimizer = 'adam',\n",
        "            metrics = ['accuracy', dice_coeff])\n",
        "\n",
        "#Defining early stopping to regularize the model and prevent overfitting\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 3, restore_best_weights = True)\n",
        "\n",
        "#Training the model with 50 epochs (it will stop training in between because of early stopping)\n",
        "unet_history = unet.fit(train_data, validation_data = [val_data],\n",
        "                        epochs = 50, callbacks = [early_stopping])"
      ],
      "metadata": {
        "id": "Uxw58Psr2u0Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}